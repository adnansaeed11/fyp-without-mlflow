{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46e65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27608a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: Quadro M1200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58403e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/campusx-team/Text-Datasets/refs/heads/main/Reddit_Data.csv')\n",
    "df.dropna(inplace=True)\n",
    "df.index.name = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e23ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'clean_comment':'text'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b54b47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  category\n",
       "id                                                             \n",
       "0    family mormon have never tried explain them t...         1\n",
       "1   buddhism has very much lot compatible with chr...         1\n",
       "2   seriously don say thing first all they won get...        -1\n",
       "3   what you have learned yours and only yours wha...         0\n",
       "4   for your own benefit you may want read living ...         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "399861cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' family mormon have never tried explain them they still stare puzzled from time time like some kind strange creature nonetheless they have come admire for the patience calmness equanimity acceptance and compassion have developed all the things buddhism teaches '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1125e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       " 1    15830\n",
       " 0    13042\n",
       "-1     8277\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcffb511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       " 1    15830\n",
       " 0    13042\n",
       "-1     8277\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b3b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fde47ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a70f45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1:0, 0:1, 1:2\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adadef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.category.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b156b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  category  label\n",
       "id                                                                    \n",
       "0    family mormon have never tried explain them t...         1      2\n",
       "1   buddhism has very much lot compatible with chr...         1      2\n",
       "2   seriously don say thing first all they won get...        -1      0\n",
       "3   what you have learned yours and only yours wha...         0      1\n",
       "4   for your own benefit you may want read living ...         1      2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "513a6596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    15830\n",
       "1    13042\n",
       "0     8277\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc37deb",
   "metadata": {},
   "source": [
    "# Training/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98432855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0013414",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, df.label.values, test_size = 0.15, random_state=17, stratify = df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "398a01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71f8e4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  category  label  \\\n",
       "id                                                                       \n",
       "0    family mormon have never tried explain them t...         1      2   \n",
       "1   buddhism has very much lot compatible with chr...         1      2   \n",
       "2   seriously don say thing first all they won get...        -1      0   \n",
       "3   what you have learned yours and only yours wha...         0      1   \n",
       "4   for your own benefit you may want read living ...         1      2   \n",
       "\n",
       "   data_type  \n",
       "id            \n",
       "0    not_set  \n",
       "1    not_set  \n",
       "2    not_set  \n",
       "3    not_set  \n",
       "4    not_set  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea79f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saeed\\AppData\\Local\\Programs\\Python\\Python39\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57eeb9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8affb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saeed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e55c2de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 0\n",
      "Columns in DataFrame: ['text', 'category', 'label', 'data_type']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples:\", df[df.data_type == 'train'].shape[0])\n",
    "print(\"Columns in DataFrame:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7711de49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'data_type': ['not_set']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'data_type':\", df['data_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be6269f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data (e.g., 80% train, 20% test)\n",
    "train_texts, test_texts = train_test_split(df['text'].tolist(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68de5e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode training data\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    train_texts,  # Use the manually split training data\n",
    "    add_special_tokens=True,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2de8541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_data_train = tokenizer.batch_encode_plus(df[df.data_type=='train'].text.values, add_special_tokens=True,return_attention_mask=True,pad_to_max_length=True,max_length=256,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da7f3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: 80% train, 20% temp (val + test)\n",
    "train_texts, temp_texts = train_test_split(df['text'].tolist(), test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: 50% val, 50% test (10% each of total)\n",
    "val_texts, test_texts = train_test_split(temp_texts, test_size=0.5, random_state=42)\n",
    "\n",
    "# Encode validation data\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    val_texts,\n",
    "    add_special_tokens=True,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d43ab4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_data_val= tokenizer.batch_encode_plus(df[df.data_type=='val'].text.values, add_special_tokens=True,return_attention_mask=True,pad_to_max_length=True,max_length=256,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e00cc255",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8962040",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val= encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43ac9c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 37149\n",
      "Train texts: 29719\n",
      "Val texts: 3715\n",
      "Test texts: 3715\n",
      "Original labels: (37149,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Train texts: {len(train_texts)}\")\n",
    "print(f\"Val texts: {len(val_texts)}\")\n",
    "print(f\"Test texts: {len(test_texts)}\")\n",
    "print(f\"Original labels: {df['label'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6f2a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all labels as numpy array first\n",
    "all_labels = df['label'].values\n",
    "\n",
    "# Split labels to exactly match text splits\n",
    "train_labels, temp_labels = train_test_split(all_labels, test_size=0.2, random_state=42)\n",
    "val_labels, test_labels = train_test_split(temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "labels_train = torch.tensor(train_labels)\n",
    "labels_val = torch.tensor(val_labels)\n",
    "labels_test = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c7287f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First encode the test texts (we already did train and val)\n",
    "encoded_data_test = tokenizer.batch_encode_plus(\n",
    "    test_texts,\n",
    "    add_special_tokens=True,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Extract test tensors\n",
    "input_ids_test = encoded_data_test['input_ids']\n",
    "attention_masks_test = encoded_data_test['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c720896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 29719\n",
      "Val dataset size: 3715\n",
      "Test dataset size: 3715\n"
     ]
    }
   ],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "\n",
    "print(f\"Train dataset size: {len(dataset_train)}\")\n",
    "print(f\"Val dataset size: {len(dataset_val)}\")\n",
    "print(f\"Test dataset size: {len(dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a59092fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29719"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "806fc714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3715"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3d3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de6fe251",
   "metadata": {},
   "source": [
    "#  Setting up BERT Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89ca3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab728679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saeed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = len(label_dict), output_attentions=False,output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9555462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebb66f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d306b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train,sampler=RandomSampler(dataset_train),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "507985ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_val = DataLoader(dataset_val,sampler=RandomSampler(dataset_val),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23b49eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saeed\\AppData\\Local\\Programs\\Python\\Python39\\python.exe\n",
      "3.9.4 (tags/v3.9.4:1f2e308, Apr  6 2021, 13:40:21) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "745ec403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "febebb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "Transformers version: 4.30.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89f9954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),lr=1e-5, #2e-5 > 5e-5\n",
    "                 eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9daf0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=6\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981a9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93cf51a6",
   "metadata": {},
   "source": [
    "# Defining our Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "587aa1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3efd82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37692528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    labels_dict_inverse = {v: k for k,v in label_dict.items()}\n",
    "\n",
    "    preds_flat = np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {labels_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd41cc",
   "metadata": {},
   "source": [
    "# Creating our Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ec86c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 8\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83bd7d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # Check PyTorch version\n",
    "print(torch.version.cuda)  # Check the CUDA version PyTorch is using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c84391e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c47a0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe89fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57a04b2739b4eea9b3556dab0eedbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dd9b8b13ca4192b1719b715498a6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1858 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm  # âœ… Use notebook-friendly tqdm\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define checkpoint directory\n",
    "checkpoint_dir = '/kaggle/working/checkpoints'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Initialize variables to track the best validation loss\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1), desc=\"Training Progress\", leave=True):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_train_total = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc=f'Epoch {epoch}', leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "\n",
    "        preds = torch.argmax(outputs[1], dim=1)\n",
    "        correct_predictions += (preds == batch[2]).sum().item()\n",
    "        total_predictions += batch[2].size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            'training_loss': '{:.3f}'.format(loss.item() / len(batch))\n",
    "        })\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    training_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    tqdm.write(f'Training Accuracy: {training_accuracy:.3f}')\n",
    "\n",
    "    # Validation\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "\n",
    "    predictions = np.argmax(predictions, axis=1).flatten()\n",
    "    val_accuracy = accuracy_score(true_vals.flatten(), predictions)\n",
    "\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "    tqdm.write(f'Validation Accuracy: {val_accuracy:.3f}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': val_loss\n",
    "        }, checkpoint_path)\n",
    "        tqdm.write(f'Checkpoint saved at {checkpoint_path}')\n",
    "\n",
    "# Save final model\n",
    "final_model_path = './final_model.pth'\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "tqdm.write(f'Final model saved at {final_model_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60aafce",
   "metadata": {},
   "source": [
    "# Loading and Evaluating our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cb766",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class(predictions, true_vals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d444b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculate validation accuracy\n",
    "predictions = np.argmax(predictions, axis=1).flatten()\n",
    "true_vals = true_vals.flatten()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_vals, predictions, target_names=['Class 0', 'Class 1', 'Class 2'])  # Change class names as per your dataset\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
