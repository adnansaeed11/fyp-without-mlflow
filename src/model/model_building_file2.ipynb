{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c46e65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27608a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: Quadro M1200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58403e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/campusx-team/Text-Datasets/refs/heads/main/Reddit_Data.csv')\n",
    "df.dropna(inplace=True)\n",
    "df.index.name = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53e23ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'clean_comment':'text'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b54b47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  category\n",
       "id                                                             \n",
       "0    family mormon have never tried explain them t...         1\n",
       "1   buddhism has very much lot compatible with chr...         1\n",
       "2   seriously don say thing first all they won get...        -1\n",
       "3   what you have learned yours and only yours wha...         0\n",
       "4   for your own benefit you may want read living ...         1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "399861cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' family mormon have never tried explain them they still stare puzzled from time time like some kind strange creature nonetheless they have come admire for the patience calmness equanimity acceptance and compassion have developed all the things buddhism teaches '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1125e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       " 1    15830\n",
       " 0    13042\n",
       "-1     8277\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcffb511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       " 1    15830\n",
       " 0    13042\n",
       "-1     8277\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98b3b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fde47ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a70f45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1:0, 0:1, 1:2\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adadef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.category.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b156b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  category  label\n",
       "id                                                                    \n",
       "0    family mormon have never tried explain them t...         1      2\n",
       "1   buddhism has very much lot compatible with chr...         1      2\n",
       "2   seriously don say thing first all they won get...        -1      0\n",
       "3   what you have learned yours and only yours wha...         0      1\n",
       "4   for your own benefit you may want read living ...         1      2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "513a6596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    15830\n",
       "1    13042\n",
       "0     8277\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc37deb",
   "metadata": {},
   "source": [
    "# Training/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98432855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0013414",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, df.label.values, test_size = 0.15, random_state=17, stratify = df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "398a01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71f8e4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  category  label  \\\n",
       "id                                                                       \n",
       "0    family mormon have never tried explain them t...         1      2   \n",
       "1   buddhism has very much lot compatible with chr...         1      2   \n",
       "2   seriously don say thing first all they won get...        -1      0   \n",
       "3   what you have learned yours and only yours wha...         0      1   \n",
       "4   for your own benefit you may want read living ...         1      2   \n",
       "\n",
       "   data_type  \n",
       "id            \n",
       "0    not_set  \n",
       "1    not_set  \n",
       "2    not_set  \n",
       "3    not_set  \n",
       "4    not_set  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea79f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saeed\\AppData\\Local\\Programs\\Python\\Python39\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57eeb9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8affb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e55c2de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 0\n",
      "Columns in DataFrame: ['text', 'category', 'label', 'data_type']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples:\", df[df.data_type == 'train'].shape[0])\n",
    "print(\"Columns in DataFrame:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7711de49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'data_type': ['not_set']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'data_type':\", df['data_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be6269f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data (e.g., 80% train, 20% test)\n",
    "train_texts, test_texts = train_test_split(df['text'].tolist(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68de5e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode training data\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    train_texts,  # Use the manually split training data\n",
    "    add_special_tokens=True,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2de8541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_data_train = tokenizer.batch_encode_plus(df[df.data_type=='train'].text.values, add_special_tokens=True,return_attention_mask=True,pad_to_max_length=True,max_length=256,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da7f3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: 80% train, 20% temp (val + test)\n",
    "train_texts, temp_texts = train_test_split(df['text'].tolist(), test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: 50% val, 50% test (10% each of total)\n",
    "val_texts, test_texts = train_test_split(temp_texts, test_size=0.5, random_state=42)\n",
    "\n",
    "# Encode validation data\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    val_texts,\n",
    "    add_special_tokens=True,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d43ab4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_data_val= tokenizer.batch_encode_plus(df[df.data_type=='val'].text.values, add_special_tokens=True,return_attention_mask=True,pad_to_max_length=True,max_length=256,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e00cc255",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8962040",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val= encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43ac9c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 37149\n",
      "Train texts: 29719\n",
      "Val texts: 3715\n",
      "Test texts: 3715\n",
      "Original labels: (37149,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Train texts: {len(train_texts)}\")\n",
    "print(f\"Val texts: {len(val_texts)}\")\n",
    "print(f\"Test texts: {len(test_texts)}\")\n",
    "print(f\"Original labels: {df['label'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6f2a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all labels as numpy array first\n",
    "all_labels = df['label'].values\n",
    "\n",
    "# Split labels to exactly match text splits\n",
    "train_labels, temp_labels = train_test_split(all_labels, test_size=0.2, random_state=42)\n",
    "val_labels, test_labels = train_test_split(temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "labels_train = torch.tensor(train_labels)\n",
    "labels_val = torch.tensor(val_labels)\n",
    "labels_test = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3c7287f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First encode the test texts (we already did train and val)\n",
    "encoded_data_test = tokenizer.batch_encode_plus(\n",
    "    test_texts,\n",
    "    add_special_tokens=True,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Extract test tensors\n",
    "input_ids_test = encoded_data_test['input_ids']\n",
    "attention_masks_test = encoded_data_test['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c720896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 29719\n",
      "Val dataset size: 3715\n",
      "Test dataset size: 3715\n"
     ]
    }
   ],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "\n",
    "print(f\"Train dataset size: {len(dataset_train)}\")\n",
    "print(f\"Val dataset size: {len(dataset_val)}\")\n",
    "print(f\"Test dataset size: {len(dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a59092fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29719"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "806fc714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3715"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3d3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de6fe251",
   "metadata": {},
   "source": [
    "#  Setting up BERT Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89ca3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab728679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = len(label_dict), output_attentions=False,output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d9555462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ebb66f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2d306b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train,sampler=RandomSampler(dataset_train),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "507985ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_val = DataLoader(dataset_val,sampler=RandomSampler(dataset_val),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23b49eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saeed\\AppData\\Local\\Programs\\Python\\Python39\\python.exe\n",
      "3.9.4 (tags/v3.9.4:1f2e308, Apr  6 2021, 13:40:21) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "745ec403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "febebb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu124\n",
      "Transformers version: 4.47.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "89f9954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),lr=1e-5, #2e-5 > 5e-5\n",
    "                 eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9daf0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981a9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93cf51a6",
   "metadata": {},
   "source": [
    "# Defining our Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "587aa1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3efd82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "37692528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    labels_dict_inverse = {v: k for k,v in label_dict.items()}\n",
    "\n",
    "    preds_flat = np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {labels_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd41cc",
   "metadata": {},
   "source": [
    "# Creating our Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ec86c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 8\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "83bd7d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # Check PyTorch version\n",
    "print(torch.version.cuda)  # Check the CUDA version PyTorch is using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c84391e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c47a0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7304dd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5dd3557ff547aca5a7b545894a7496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67b03be5aa34484a94a5dfff407ac8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1858 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     53\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 55\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch))})\n\u001b[0;32m     57\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m loss_train_avg \u001b[38;5;241m=\u001b[39m loss_train_total \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader_train)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define checkpoint directory\n",
    "checkpoint_dir = '/kaggle/working/checkpoints'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Initialize variables to track the best validation loss\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_train_total = 0\n",
    "    correct_predictions = 0  # To keep track of correct predictions\n",
    "    total_predictions = 0     # To keep track of total predictions\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "\n",
    "        # Get predictions\n",
    "        preds = torch.argmax(outputs[1], dim=1)  # Assuming the logits are in outputs[1]\n",
    "\n",
    "        # Update correct and total counts\n",
    "        correct_predictions += (preds == batch[2]).sum().item()\n",
    "        total_predictions += batch[2].size(0)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    training_accuracy = correct_predictions / total_predictions  # Calculate training accuracy\n",
    "\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    tqdm.write(f'Training Accuracy: {training_accuracy:.3f}')  # Print training accuracy\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    predictions = np.argmax(predictions, axis=1).flatten()\n",
    "    val_accuracy = accuracy_score(true_vals.flatten(), predictions)\n",
    "\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "    tqdm.write(f'Validation Accuracy: {val_accuracy:.3f}')\n",
    "\n",
    "    # Save checkpoint if the validation loss improved\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': val_loss\n",
    "        }, checkpoint_path)\n",
    "        tqdm.write(f'Checkpoint saved at {checkpoint_path}')\n",
    "\n",
    "# Save the final model after training\n",
    "final_model_path = './final_model.pth'\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "tqdm.write(f'Final model saved at {final_model_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9d1567e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU name: Quadro M1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [06:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 45\u001b[0m loss_train_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[0;32m     48\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlogits\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Check GPU availability and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU name: {torch.cuda.get_device_name(0)}\") if torch.cuda.is_available() else print(\"No GPU available\")\n",
    "\n",
    "# Define checkpoint directory\n",
    "checkpoint_dir = '/kaggle/working/checkpoints'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Initialize variables to track the best validation loss\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc=f'Epoch {epoch}', leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Move batch tensors to GPU\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "\n",
    "        # Get predictions\n",
    "        logits = outputs[1] if isinstance(outputs, tuple) else outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        correct_predictions += (preds == batch[2]).sum().item()\n",
    "        total_predictions += batch[2].size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({'training_loss': f'{loss.item()/len(batch):.3f}'})\n",
    "\n",
    "    # Training metrics\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    training_accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    print(f'\\nEpoch {epoch}')\n",
    "    print(f'Training loss: {loss_train_avg}')\n",
    "    print(f'Training Accuracy: {training_accuracy:.3f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    predictions = np.argmax(predictions, axis=1).flatten()\n",
    "    val_accuracy = accuracy_score(true_vals.flatten(), predictions)\n",
    "\n",
    "    print(f'Validation loss: {val_loss}')\n",
    "    print(f'F1 Score (weighted): {val_f1}')\n",
    "    print(f'Validation Accuracy: {val_accuracy:.3f}')\n",
    "\n",
    "    # Save checkpoint if improved\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': val_loss\n",
    "        }, checkpoint_path)\n",
    "        print(f'Checkpoint saved at {checkpoint_path}')\n",
    "\n",
    "# Final model save\n",
    "final_model_path = './final_model.pth'\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f'Final model saved at {final_model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf7257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
